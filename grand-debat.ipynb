{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Détection de thème sur une question environnement du grand débat</h2></center>\n",
    "\n",
    "Fork du projet TALAGRAND (https://github.com/Quantmetry/grand-debat) qui met à disposition des techniques d'IA pour appréhender le nombre important de réponses au grand débat.  \n",
    "\n",
    "De même mon but est d'essayer des techniques d'extraction de thème (topic detection) sur des questions du grand débat. Pour cet essai j'ai pris : \"de quelle manière votre vie quotidienne est-elle touchée par le changement climatique ?\").  \n",
    "J'ai tenté de le comparer ensuite à la synthèse \"officielle\" réalisée par OpinionWay : \n",
    "https://granddebat.fr/media/default/0001/01/b88758e8caa2733bec607a74b3b5371cc0a3b420.pdf\n",
    "\n",
    "\n",
    "Tel quel le projet de départ TALAGRAND m'a donné des thèmes difficilement interprétables. Dans cette implémentation j'ai modifié la préparation de données grâce à la librairie  **spacy (lemmatisation, filtrage par POS)**, utilisé le même algo de **LDA de scikit-learn** que le projet initial, et déterminé le nombre de thèmes grâce au **score de cohérence** fourni par la librairie **gensim**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Téléchargement des données\n",
    "-  Récupérer la liste des thèmes en analysant le site du Grand Débat\n",
    "-  Sélectionner un thème en modifiant la variable `selected_theme`\n",
    "-  Télécharger ensuite le fichier json le plus récent associé à un thème depuis datagouv.fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grand_debat.downloading import download_data, get_themes\n",
    "\n",
    "#themes = get_themes() # not working\n",
    "\n",
    "themes = {\"1 L'organisation de l'État et des services publics\": \n",
    "              \"http://opendata.auth-6f31f706db6f4a24b55f42a6a79c5086.storage.sbg.cloud.ovh.net/\"+\n",
    "              \"2019-03-21/ORGANISATION_DE_LETAT_ET_DES_SERVICES_PUBLICS.json\",\n",
    "          \"2 la-transition-ecologique\": \n",
    "              \"http://opendata.auth-6f31f706db6f4a24b55f42a6a79c5086.storage.sbg.cloud.ovh.net/2019-03-21/\"+\n",
    "              \"LA_TRANSITION_ECOLOGIQUE.json\",\n",
    "          # 2 autres thèmes (fiscalité, démocratie) à voir ici:\n",
    "          # https://granddebat.fr/pages/donnees-ouvertes\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choisir le numéro associé au thème que l'on souhaite étudier\n",
    "selected_theme = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download_data(themes, selected_theme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des données\n",
    "-  Charger le fichier json précédemment téléchargé\n",
    "-  Afficher les différentes questions associées au thème sélectionné\n",
    "-  Sélectionner une question à étudier (variable `selected_question`)\n",
    "-  Afficher le nombre de réponses existantes correspondant à cette question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grand_debat.loading import load_answers, get_path, display_questions_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_path(themes, selected_theme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qestion id : UXVlc3Rpb246MTYw\n",
      "Quel est aujourd'hui pour vous le problème concret le plus important dans le domaine de l'environnement ?\n",
      "\n",
      "Qestion id : UXVlc3Rpb246MTYx\n",
      "Que faudrait-il faire selon vous pour apporter des réponses à ce problème ?\n",
      "\n",
      "Qestion id : UXVlc3Rpb246MTQ2\n",
      "Diriez-vous que votre vie quotidienne est aujourd'hui touchée par le changement climatique ?\n",
      "\n",
      "Qestion id : UXVlc3Rpb246MTQ3\n",
      "Si oui, de quelle manière votre vie quotidienne est-elle touchée par le changement climatique ?\n",
      "\n",
      "Qestion id : UXVlc3Rpb246MTQ4\n",
      "À titre personnel, pensez-vous pouvoir contribuer à protéger l'environnement ?\n",
      "\n",
      "Qestion id : UXVlc3Rpb246MTQ5\n",
      "Si oui, que faites-vous aujourd'hui pour protéger l'environnement et/ou que pourriez-vous faire ?\n",
      "\n",
      "Qestion id : UXVlc3Rpb246MTUw\n",
      "Qu'est-ce qui pourrait vous inciter à changer vos comportements comme par exemple mieux entretenir et régler votre chauffage, modifier votre manière de conduire ou renoncer à prendre votre véhicule pour de très petites distances ?\n",
      "\n",
      "Qestion id : UXVlc3Rpb246MTUx\n",
      "Quelles seraient pour vous les solutions les plus simples et les plus supportables sur un plan financier pour vous inciter à changer vos comportements ?\n",
      "\n",
      "Qestion id : UXVlc3Rpb246MTUy\n",
      "Par rapport à votre mode de chauffage actuel, pensez-vous qu'il existe des solutions alternatives plus écologiques ?\n",
      "\n",
      "Qestion id : UXVlc3Rpb246MTUz\n",
      "Si oui, que faudrait-il faire pour vous convaincre ou vous aider à changer de mode de chauffage ?\n",
      "\n",
      "Qestion id : UXVlc3Rpb246MTU0\n",
      "Avez-vous pour vos déplacements quotidiens la possibilité de recourir à des solutions de mobilité alternatives à la voiture individuelle comme les transports en commun, le covoiturage, l'auto-partage, le transport à la demande, le vélo, etc. ?\n",
      "\n",
      "Qestion id : UXVlc3Rpb246MTU1\n",
      "Si oui, que faudrait-il faire pour vous convaincre ou vous aider à utiliser ces solutions alternatives ?\n",
      "\n",
      "Qestion id : UXVlc3Rpb246MjA3\n",
      "Si non, quelles sont les solutions de mobilité alternatives que vous souhaiteriez pouvoir utiliser ?\n",
      "\n",
      "Qestion id : UXVlc3Rpb246MTU3\n",
      "Et qui doit selon vous se charger de vous proposer ce type de solutions alternatives ?\n",
      "\n",
      "Qestion id : UXVlc3Rpb246MTU4\n",
      "Que pourrait faire la France pour faire partager ses choix en matière d'environnement au niveau européen et international ?\n",
      "\n",
      "Qestion id : UXVlc3Rpb246MTU5\n",
      "Y a-t-il d'autres points sur la transition écologique sur lesquels vous souhaiteriez vous exprimer ?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_questions_from_json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indiquer ici l'identifiant associé à la question étudiée\n",
    "selected_question = 'UXVlc3Rpb246MTQ3' # Si oui, de quelle manière votre vie quotidienne est-elle touchée ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "153809it [00:07, 21000.80it/s]\n"
     ]
    }
   ],
   "source": [
    "answers = load_answers(path, selected_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de réponses analysées : 92795\n"
     ]
    }
   ],
   "source": [
    "print(\"Nombre de réponses analysées :\", len(answers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Détection de thèmes</h2>\n",
    "\n",
    "-  Détecter les thèmes principaux associés à la question sélectionnée en utilisant l'algorithme **LDA** (Latent Dirichlet Allocation)\n",
    "-  Le resultat de l'analyse se trouve dans le fichier pyLDAVIS_tf.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlesprat/miniconda3/envs/tf/lib/python3.7/site-packages/scipy/sparse/sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n",
      "/Users/charlesprat/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/framework/dtypes.py:597: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.object,\n",
      "/Users/charlesprat/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/framework/dtypes.py:605: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.bool,\n",
      "/Users/charlesprat/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/framework/dtypes.py:639: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.object,\n",
      "/Users/charlesprat/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/framework/dtypes.py:649: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.bool,\n",
      "/Users/charlesprat/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py:106: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.object:\n",
      "/Users/charlesprat/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py:108: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.bool:\n",
      "/Users/charlesprat/miniconda3/envs/tf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:568: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  (np.object, string),\n",
      "/Users/charlesprat/miniconda3/envs/tf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:569: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  (np.bool, bool),\n",
      "/Users/charlesprat/miniconda3/envs/tf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:593: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  types_pb2.DT_STRING: np.object,\n",
      "/Users/charlesprat/miniconda3/envs/tf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:597: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  types_pb2.DT_BOOL: np.bool,\n",
      "/Users/charlesprat/miniconda3/envs/tf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:614: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  types_pb2.DT_STRING_REF: np.object,\n",
      "/Users/charlesprat/miniconda3/envs/tf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:619: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  types_pb2.DT_BOOL_REF: np.bool,\n",
      "/Users/charlesprat/miniconda3/envs/tf/lib/python3.7/site-packages/tensorboard/util/tensor_util.py:100: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.object: SlowAppendObjectArrayToTensorProto,\n",
      "/Users/charlesprat/miniconda3/envs/tf/lib/python3.7/site-packages/tensorboard/util/tensor_util.py:101: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.bool: SlowAppendBoolArrayToTensorProto,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'grand_debat.theme_detection' from '/Users/charlesprat/RepoGit/grand-debat/grand_debat/theme_detection.py'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import importlib\n",
    "import grand_debat.theme_detection as td\n",
    "importlib.reload(td)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation des données\n",
    "\n",
    "Tokenisation, lemmatisation, filtrage sur type (POS NOUN et ADJ) et stop words de spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load spacy pipeline\n",
      "tokenizing datas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92795/92795 [02:13<00:00, 695.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting countvectorizer\n",
      "data preparation done\n"
     ]
    }
   ],
   "source": [
    "gd_prep = td.GDebatDataPreparation(answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recherche du nombre optimal de thèmes pour l'entrée de la LDA\n",
    "\n",
    "On se base sur le \"coherence score\".  \n",
    "https://svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'grand_debat.theme_detection' from '/Users/charlesprat/RepoGit/grand-debat/grand_debat/theme_detection.py'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import default_rng\n",
    "rng = default_rng(seed=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = [3,4,5,6,7,10,12]\n",
    "answs_samples = rng.choice(gd_prep.answ_lems, size=10000, replace=False).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute lda for 3 topics\n",
      "Lda done, coherence 0.591\n",
      "compute lda for 4 topics\n",
      "Lda done, coherence 0.598\n",
      "compute lda for 5 topics\n",
      "Lda done, coherence 0.434\n",
      "compute lda for 6 topics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process AccumulatingWorker-34:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/charlesprat/miniconda3/envs/tf/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/Users/charlesprat/miniconda3/envs/tf/lib/python3.7/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/Users/charlesprat/miniconda3/envs/tf/lib/python3.7/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/Users/charlesprat/miniconda3/envs/tf/lib/python3.7/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/Users/charlesprat/miniconda3/envs/tf/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/Users/charlesprat/miniconda3/envs/tf/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/Users/charlesprat/miniconda3/envs/tf/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nb/v61jd0_j06bbnbf079ftm75c0000gn/T/ipykernel_45998/818950178.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m v_coh, l_topics, best_n = td.compute_coherence_vs_ntopics(\n\u001b[0;32m----> 2\u001b[0;31m     answs_samples, gd_prep, num_topics=num_topics, lambda_coh=0.3)\n\u001b[0m",
      "\u001b[0;32m~/RepoGit/grand-debat/grand_debat/theme_detection.py\u001b[0m in \u001b[0;36mcompute_coherence_vs_ntopics\u001b[0;34m(responses, data_prep, num_topics, lambda_coh)\u001b[0m\n\u001b[1;32m    151\u001b[0m         cm = CoherenceModel(topics=topics, texts=responses,\n\u001b[1;32m    152\u001b[0m                             dictionary=dictionary, coherence='c_v')\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mcoherence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_coherence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# get coherence value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0mv_coh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoherence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Lda done, coherence {:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoherence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.7/site-packages/gensim/models/coherencemodel.py\u001b[0m in \u001b[0;36mget_coherence\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \"\"\"\n\u001b[0;32m--> 615\u001b[0;31m         \u001b[0mconfirmed_measures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_coherence_per_topic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate_measures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfirmed_measures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.7/site-packages/gensim/models/coherencemodel.py\u001b[0m in \u001b[0;36mget_coherence_per_topic\u001b[0;34m(self, segmented_topics, with_std, with_support)\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0msegmented_topics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeasure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accumulator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_probabilities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegmented_topics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_std\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwith_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_support\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwith_support\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.7/site-packages/gensim/models/coherencemodel.py\u001b[0m in \u001b[0;36mestimate_probabilities\u001b[0;34m(self, segmented_topics)\u001b[0m\n\u001b[1;32m    545\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeyed_vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accumulator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeasure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accumulator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.7/site-packages/gensim/topic_coherence/probability_estimation.py\u001b[0m in \u001b[0;36mp_boolean_sliding_window\u001b[0;34m(texts, segmented_topics, dictionary, window_size, processes)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0maccumulator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallelWordOccurrenceAccumulator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"using %s to estimate probabilities from sliding windows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccumulator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0maccumulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.7/site-packages/gensim/topic_coherence/text_analysis.py\u001b[0m in \u001b[0;36maccumulate\u001b[0;34m(self, texts, window_size)\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0minterrupted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0maccumulators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate_workers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterrupted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_accumulators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccumulators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.7/site-packages/gensim/topic_coherence/text_analysis.py\u001b[0m in \u001b[0;36mterminate_workers\u001b[0;34m(self, input_q, output_q, workers, interrupted)\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0maccumulators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccumulators\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0maccumulators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_q\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%d accumulators retrieved from output queue\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccumulators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'A'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "v_coh, l_topics, best_n = td.compute_coherence_vs_ntopics(\n",
    "    answs_samples, gd_prep, num_topics=num_topics, lambda_coh=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "f,ax = plt.subplots()\n",
    "\n",
    "pd.Series(v_coh, index=[len(topic) for topic in l_topics]).plot(ax=ax)\n",
    "ax.grid()\n",
    "#ax.set_ylim(0.2,0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA sur l'ensemble des donnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'grand_debat.theme_detection' from '/Users/charlesprat/RepoGit/grand-debat/grand_debat/theme_detection.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plusieurs essais random me montrent que sur la question sélectionnée UXVlc3Rpb246MTQ3\n",
    "# le premier maximum de la coherence se trouve très souvent entre 5 et 6. \n",
    "\n",
    "n_topics = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_detector = td.GDebatTopicDetection(gd_prep, n_topics, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 100\n",
      "iteration: 2 of max_iter: 100\n",
      "iteration: 3 of max_iter: 100\n",
      "iteration: 4 of max_iter: 100, perplexity: 1093.3305\n",
      "iteration: 5 of max_iter: 100\n",
      "iteration: 6 of max_iter: 100\n",
      "iteration: 7 of max_iter: 100\n",
      "iteration: 8 of max_iter: 100, perplexity: 988.9852\n",
      "iteration: 9 of max_iter: 100\n",
      "iteration: 10 of max_iter: 100\n",
      "iteration: 11 of max_iter: 100\n",
      "iteration: 12 of max_iter: 100, perplexity: 963.4115\n",
      "iteration: 13 of max_iter: 100\n",
      "iteration: 14 of max_iter: 100\n",
      "iteration: 15 of max_iter: 100\n",
      "iteration: 16 of max_iter: 100, perplexity: 951.7276\n",
      "iteration: 17 of max_iter: 100\n",
      "iteration: 18 of max_iter: 100\n",
      "iteration: 19 of max_iter: 100\n",
      "iteration: 20 of max_iter: 100, perplexity: 944.7581\n",
      "iteration: 21 of max_iter: 100\n",
      "iteration: 22 of max_iter: 100\n",
      "iteration: 23 of max_iter: 100\n",
      "iteration: 24 of max_iter: 100, perplexity: 939.0890\n",
      "iteration: 25 of max_iter: 100\n",
      "iteration: 26 of max_iter: 100\n",
      "iteration: 27 of max_iter: 100\n",
      "iteration: 28 of max_iter: 100, perplexity: 935.8708\n",
      "iteration: 29 of max_iter: 100\n",
      "iteration: 30 of max_iter: 100\n",
      "iteration: 31 of max_iter: 100\n",
      "iteration: 32 of max_iter: 100, perplexity: 934.3437\n",
      "iteration: 33 of max_iter: 100\n",
      "iteration: 34 of max_iter: 100\n",
      "iteration: 35 of max_iter: 100\n",
      "iteration: 36 of max_iter: 100, perplexity: 933.2650\n",
      "iteration: 37 of max_iter: 100\n",
      "iteration: 38 of max_iter: 100\n",
      "iteration: 39 of max_iter: 100\n",
      "iteration: 40 of max_iter: 100, perplexity: 931.9287\n",
      "iteration: 41 of max_iter: 100\n",
      "iteration: 42 of max_iter: 100\n",
      "iteration: 43 of max_iter: 100\n",
      "iteration: 44 of max_iter: 100, perplexity: 929.4845\n",
      "iteration: 45 of max_iter: 100\n",
      "iteration: 46 of max_iter: 100\n",
      "iteration: 47 of max_iter: 100\n",
      "iteration: 48 of max_iter: 100, perplexity: 926.5772\n",
      "iteration: 49 of max_iter: 100\n",
      "iteration: 50 of max_iter: 100\n",
      "iteration: 51 of max_iter: 100\n",
      "iteration: 52 of max_iter: 100, perplexity: 924.3504\n",
      "iteration: 53 of max_iter: 100\n",
      "iteration: 54 of max_iter: 100\n",
      "iteration: 55 of max_iter: 100\n",
      "iteration: 56 of max_iter: 100, perplexity: 922.9765\n",
      "iteration: 57 of max_iter: 100\n",
      "iteration: 58 of max_iter: 100\n",
      "iteration: 59 of max_iter: 100\n",
      "iteration: 60 of max_iter: 100, perplexity: 922.3601\n",
      "iteration: 61 of max_iter: 100\n",
      "iteration: 62 of max_iter: 100\n",
      "iteration: 63 of max_iter: 100\n",
      "iteration: 64 of max_iter: 100, perplexity: 922.0787\n",
      "Topic detection done\n",
      "LDA visualization in pyLDAVIS_tf.html\n"
     ]
    }
   ],
   "source": [
    "topic_detector.compute_topic_detection(data_bow=gd_prep.answ_bow, LDAVis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['saison', 'température', 'disparition', 'climatique', 'espèce', 'dérèglement', 'oiseau', 'insecte', 'changement']\n",
      "['eau', 'naturel', 'catastrophe', 'littoral', 'glacier', 'érosion', 'mer', 'montagne', 'sécheresse']\n",
      "['climatique', 'vie', 'changement', 'quotidien', 'enfant', 'monde', 'impact', 'avenir', 'planète']\n",
      "['pollution', 'air', 'ville', 'santé', 'allergie', 'problème', 'qualité', 'respiratoire', 'maladie']\n",
      "['sécheresse', 'canicule', 'inondation', 'tempête', 'chaleur', 'fréquent', 'violent', 'climatique', 'période']\n",
      "['hiver', 'été', 'chaud', 'année', 'neige', 'froid', 'chaleur', 'jardin', 'an']\n"
     ]
    }
   ],
   "source": [
    "for topic in topic_detector.get_topics_by_relevance(lambd=1):\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interprétation et résumé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import grand_debat.text_summarization as ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/92795 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence segmentation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92795/92795 [02:04<00:00, 746.52it/s]\n",
      "  0%|          | 0/31176 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31176/31176 [00:37<00:00, 835.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA transformation\n"
     ]
    }
   ],
   "source": [
    "titles = ts.create_titles(answers, topic_detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hausses des assurances',\n",
       " 'Biodiversité Frustration vis-à-vis du gaspillage énergique (transport, chauffage, nourriture biologique',\n",
       " 'Par les mensonges entendus dans les médias.',\n",
       " 'Variation de température + importante. Hiver doux ou tardif, été caniculaire. Inondations bord de Seine.',\n",
       " \"Plutôt renseigné sur ces questions, l'immobilisme général et les faux-semblants instillent petit à petit une terrible dépression, un pessimisme qui pourrait devenir un véritable problème de santé publique.\",\n",
       " 'Catastrophes naturelles et migrations']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J'interprête \"à la main\" chacun des thèmes comme cela :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_names = [\"Biodiversité\", \"Pollution de l'air / santé\", \"Événements extrêmes\", \n",
    "               \"Réchauffement / saisons déréglées\", \n",
    "               \"Inquiétude avenir / impact sur nos dépenses\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "topics_pct = pd.Series(index=topic_names, \n",
    "                       data=(tf_lda.transform(tf_bow.transform(answ_lems)) >0.2).mean(axis=0)*100)\n",
    "\n",
    "f,ax = plt.subplots()\n",
    "topics_pct.sort_values().plot(kind=\"barh\")\n",
    "ax.grid()\n",
    "ax.set_xlabel(\"%\")\n",
    "ax.set_title(\"Pourcentage des réponses\\nmentionnant les thèmes suivants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topics OpinionWay \n",
    "# https://granddebat.fr/media/default/0001/01/b88758e8caa2733bec607a74b3b5371cc0a3b420.pdf \n",
    "topics_ow = pd.Series(\n",
    "    {\"Les épisodes de chaleur, les sécheresses\": 24.6,\n",
    "    \"Des événements climatiques plus fréquents\": 16.5,\n",
    "    \"L'impact lié à la qualité de l'air\": 12.4,\n",
    "    \"Autres impacts liés à la pollution\": 12.2,\n",
    "    \"L'impact lié à l'eau : pollution, inondations, consommation\": 9.3,\n",
    "    \"Les conséquences sur la santé\": 11.9,\n",
    "     \"L'impact lié à la faune, la flore, la biodiversité\": 8.4,\n",
    "     \"Autres éléments\": 3.2,\n",
    "     \"Autres mentions concernant l'environnement\": 2.4,\n",
    "     \"L'impact lié au littoral et à la mer\": 1.4,\n",
    "     \"L'impact lié aux dépenses, prix, taxes\": 1.3,\n",
    "     \"Trop de déchets, le problème de la gestion des déchets\": 1.3,\n",
    "     \"L'impact lié à l'agriculture\": 1.2,\n",
    "     \"L'impact lié aux transports\": 1.1,\n",
    "     \"L'immigration de réfugiés climatiques\": 0.6\n",
    "    }\n",
    ")\n",
    "\n",
    "f,ax = plt.subplots()\n",
    "topics_ow.sort_values().plot(kind=\"barh\",ax=ax)\n",
    "ax.grid()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Résumé de chaque thème</h2>\n",
    "-  Résumer un grand thème en utilisant TextRank, technique de résumé extractive\n",
    "-  Spécifier le nombre de phrases que l'on souhaite pour former le résumé dans la variable `sn`\n",
    "-  Les résultats se situent dans le fichier demo.docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grand_debat.text_summarization import prepare_data, apply_page_rank_algorithm, create_titles\n",
    "from grand_debat.vectorization import sentence_to_vec\n",
    "from grand_debat.clusterisation import apply_clusterisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer le document texte en un ensemble de phrases dont la typographie est standardisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sentences = prepare_data(data_theme_response_dict, selected_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupérer la phrase la plus caractéristique de chaque thème"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentences_mixture_topics, title_sentences, titles = create_titles(clean_sentences, tf_bow, tf_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Associer à chaque phrase du corpus son thème (issu de **LDA**) le plus carctéristique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_paragraph = apply_clusterisation(sentences_mixture_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Représenter chaque phrase sous la forme d'un vecteur dense. Ces vecteurs sont obtenus à partir d'embeddings entraînés à partir de l'ensemble des contributions au Grand Débat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_vectors, word_embeddings = sentence_to_vec(clean_sentences, file_model='data/word2vec.10k.100d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On applique alors l'algorithme **TextRank** à l'ensemble des phrases d'un thème pour en extraire les phrases carctéristiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indiquer le nombre de phrases qui formeront le résumé\n",
    "sn = 10\n",
    "apply_page_rank_algorithm(clean_sentences, sentences_paragraph, word_embeddings, sn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
