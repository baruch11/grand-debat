{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Traitement Automatique du LAngage au service du GRANd Débat National</h2></center>\n",
    "\n",
    "Fork du projet TALAGRAND disponible ici : https://github.com/Quantmetry/grand-debat  \n",
    "Mots clés : **NLP, TAL, LDA, Embeddings, TextRank**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Téléchargement des données\n",
    "-  Récupérer la liste des thèmes en analysant le site du Grand Débat\n",
    "-  Sélectionner un thème en modifiant la variable `selected_theme`\n",
    "-  Télécharger ensuite le fichier json le plus récent associé à un thème depuis datagouv.fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grand_debat.downloading import download_data, get_themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "themes = get_themes() # not working\n",
    "list(themes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "themes = {\"1 L'organisation de l'État et des services publics\": \n",
    "              \"http://opendata.auth-6f31f706db6f4a24b55f42a6a79c5086.storage.sbg.cloud.ovh.net/\"+\n",
    "              \"2019-03-21/ORGANISATION_DE_LETAT_ET_DES_SERVICES_PUBLICS.json\",\n",
    "          \"2 la-transition-ecologique\": \n",
    "              \"http://opendata.auth-6f31f706db6f4a24b55f42a6a79c5086.storage.sbg.cloud.ovh.net/2019-03-21/\"+\n",
    "              \"LA_TRANSITION_ECOLOGIQUE.json\"\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choisir le numéro associé au thème que l'on souhaite étudier\n",
    "selected_theme = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download_data(themes, selected_theme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des données\n",
    "-  Charger le fichier json précédemment téléchargé\n",
    "-  Afficher les différentes questions associées au thème sélectionné\n",
    "-  Sélectionner une question à étudier (variable `selected_question`)\n",
    "-  Afficher le nombre de réponses existantes correspondant à cette question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grand_debat.loading import load_data, load_question, get_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_path(themes, selected_theme)\n",
    "data_theme_json = load_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID : UXVlc3Rpb246MTYw - Question: Quel est aujourd'hui pour vous le problème concret le plus important dans le domaine de l'environnement ?\n",
      "\n",
      "ID : UXVlc3Rpb246MTYx - Question: Que faudrait-il faire selon vous pour apporter des réponses à ce problème ?\n",
      "\n",
      "ID : UXVlc3Rpb246MTQ2 - Question: Diriez-vous que votre vie quotidienne est aujourd'hui touchée par le changement climatique ?\n",
      "\n",
      "ID : UXVlc3Rpb246MTQ3 - Question: Si oui, de quelle manière votre vie quotidienne est-elle touchée par le changement climatique ?\n",
      "\n",
      "ID : UXVlc3Rpb246MTQ4 - Question: À titre personnel, pensez-vous pouvoir contribuer à protéger l'environnement ?\n",
      "\n",
      "ID : UXVlc3Rpb246MTQ5 - Question: Si oui, que faites-vous aujourd'hui pour protéger l'environnement et/ou que pourriez-vous faire ?\n",
      "\n",
      "ID : UXVlc3Rpb246MTUw - Question: Qu'est-ce qui pourrait vous inciter à changer vos comportements comme par exemple mieux entretenir et régler votre chauffage, modifier votre manière de conduire ou renoncer à prendre votre véhicule pour de très petites distances ?\n",
      "\n",
      "ID : UXVlc3Rpb246MTUx - Question: Quelles seraient pour vous les solutions les plus simples et les plus supportables sur un plan financier pour vous inciter à changer vos comportements ?\n",
      "\n",
      "ID : UXVlc3Rpb246MTUy - Question: Par rapport à votre mode de chauffage actuel, pensez-vous qu'il existe des solutions alternatives plus écologiques ?\n",
      "\n",
      "ID : UXVlc3Rpb246MTUz - Question: Si oui, que faudrait-il faire pour vous convaincre ou vous aider à changer de mode de chauffage ?\n",
      "\n",
      "ID : UXVlc3Rpb246MTU0 - Question: Avez-vous pour vos déplacements quotidiens la possibilité de recourir à des solutions de mobilité alternatives à la voiture individuelle comme les transports en commun, le covoiturage, l'auto-partage, le transport à la demande, le vélo, etc. ?\n",
      "\n",
      "ID : UXVlc3Rpb246MTU1 - Question: Si oui, que faudrait-il faire pour vous convaincre ou vous aider à utiliser ces solutions alternatives ?\n",
      "\n",
      "ID : UXVlc3Rpb246MjA3 - Question: Si non, quelles sont les solutions de mobilité alternatives que vous souhaiteriez pouvoir utiliser ?\n",
      "\n",
      "ID : UXVlc3Rpb246MTU3 - Question: Et qui doit selon vous se charger de vous proposer ce type de solutions alternatives ?\n",
      "\n",
      "ID : UXVlc3Rpb246MTU4 - Question: Que pourrait faire la France pour faire partager ses choix en matière d'environnement au niveau européen et international ?\n",
      "\n",
      "ID : UXVlc3Rpb246MTU5 - Question: Y a-t-il d'autres points sur la transition écologique sur lesquels vous souhaiteriez vous exprimer ?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions_id = [r['questionId'] for r in data_theme_json[0]['responses']]\n",
    "questions_title = [r['questionTitle'] for r in data_theme_json[0]['responses']]\n",
    "for id, title in zip(questions_id, questions_title):\n",
    "    print(\"ID : {} - Question: {}\".format(id, title))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indiquer ici l'identifiant associé à la question étudiée\n",
    "selected_question = 'UXVlc3Rpb246MTQ3' # Si oui, de quelle manière votre vie quotidienne est-elle touchée ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de réponses analysées : 92792\n"
     ]
    }
   ],
   "source": [
    "selected_question = str(selected_question)\n",
    "data_theme_response_dict = load_question(questions_id, data_theme_json, selected_question)\n",
    "print(\"Nombre de réponses analysées :\", len(data_theme_response_dict[selected_question]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Pollution de l'air, pollution de nos aliments, maladie chronique dans mon entourage, maladie digestive\",\n",
       " \"Réchauffement climatique évident , températures en hausse permanente et changements brutaux d'un point de vue météo avec trés gros orages . La question est mal posée à mon avis .\",\n",
       " 'Climat',\n",
       " \"la qualité de l'air n'est pas la même selon la météo\"]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def inspect_responses(data_theme_json, selected_question):\n",
    "    resp_flat = pd.DataFrame.from_records(\n",
    "        pd.json_normalize(data_theme_json[:10])[\"responses\"].explode().values)\n",
    "    return resp_flat.loc[resp_flat[\"questionId\"] == selected_question, \"value\"].dropna()\n",
    "\n",
    "list(inspect_responses(data_theme_json, selected_question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h2>Détection de thèmes</h2>\n",
    "-  Détecter les thèmes principaux associés à la question sélectionnée en utilisant l'algorithme **LDA** (Latent Dirichlet Allocation)\n",
    "-  Le resultat de l'analyse se trouve dans le fichier pyLDAVIS_tf.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy preparation\n",
    "import spacy\n",
    "nlp = spacy.load(\"fr_core_news_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'grand_debat.theme_detection' from '/Users/charlesprat/RepoGit/grand-debat/grand_debat/theme_detection.py'>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import importlib\n",
    "import grand_debat.theme_detection as td\n",
    "importlib.reload(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import default_rng\n",
    "rng = default_rng(seed=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "answs = rng.choice(data_theme_response_dict[selected_question], size=10000, replace=False).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:14<00:00, 677.15it/s]\n"
     ]
    }
   ],
   "source": [
    "answ_lems = td.lemmatize_answers(answs, nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 100\n",
      "iteration: 2 of max_iter: 100\n",
      "iteration: 3 of max_iter: 100\n",
      "iteration: 4 of max_iter: 100, perplexity: 608.6675\n",
      "iteration: 5 of max_iter: 100\n",
      "iteration: 6 of max_iter: 100\n",
      "iteration: 7 of max_iter: 100\n",
      "iteration: 8 of max_iter: 100, perplexity: 565.0849\n",
      "iteration: 9 of max_iter: 100\n",
      "iteration: 10 of max_iter: 100\n",
      "iteration: 11 of max_iter: 100\n",
      "iteration: 12 of max_iter: 100, perplexity: 551.4498\n",
      "iteration: 13 of max_iter: 100\n",
      "iteration: 14 of max_iter: 100\n",
      "iteration: 15 of max_iter: 100\n",
      "iteration: 16 of max_iter: 100, perplexity: 543.9126\n",
      "iteration: 17 of max_iter: 100\n",
      "iteration: 18 of max_iter: 100\n",
      "iteration: 19 of max_iter: 100\n",
      "iteration: 20 of max_iter: 100, perplexity: 539.0742\n",
      "iteration: 21 of max_iter: 100\n",
      "iteration: 22 of max_iter: 100\n",
      "iteration: 23 of max_iter: 100\n",
      "iteration: 24 of max_iter: 100, perplexity: 536.1698\n",
      "iteration: 25 of max_iter: 100\n",
      "iteration: 26 of max_iter: 100\n",
      "iteration: 27 of max_iter: 100\n",
      "iteration: 28 of max_iter: 100, perplexity: 533.8548\n",
      "iteration: 29 of max_iter: 100\n",
      "iteration: 30 of max_iter: 100\n",
      "iteration: 31 of max_iter: 100\n",
      "iteration: 32 of max_iter: 100, perplexity: 532.4981\n",
      "iteration: 33 of max_iter: 100\n",
      "iteration: 34 of max_iter: 100\n",
      "iteration: 35 of max_iter: 100\n",
      "iteration: 36 of max_iter: 100, perplexity: 531.5348\n",
      "iteration: 37 of max_iter: 100\n",
      "iteration: 38 of max_iter: 100\n",
      "iteration: 39 of max_iter: 100\n",
      "iteration: 40 of max_iter: 100, perplexity: 530.5496\n",
      "iteration: 41 of max_iter: 100\n",
      "iteration: 42 of max_iter: 100\n",
      "iteration: 43 of max_iter: 100\n",
      "iteration: 44 of max_iter: 100, perplexity: 529.5418\n",
      "iteration: 45 of max_iter: 100\n",
      "iteration: 46 of max_iter: 100\n",
      "iteration: 47 of max_iter: 100\n",
      "iteration: 48 of max_iter: 100, perplexity: 528.4274\n",
      "iteration: 49 of max_iter: 100\n",
      "iteration: 50 of max_iter: 100\n",
      "iteration: 51 of max_iter: 100\n",
      "iteration: 52 of max_iter: 100, perplexity: 527.4828\n",
      "iteration: 53 of max_iter: 100\n",
      "iteration: 54 of max_iter: 100\n",
      "iteration: 55 of max_iter: 100\n",
      "iteration: 56 of max_iter: 100, perplexity: 526.8776\n",
      "iteration: 57 of max_iter: 100\n",
      "iteration: 58 of max_iter: 100\n",
      "iteration: 59 of max_iter: 100\n",
      "iteration: 60 of max_iter: 100, perplexity: 526.1819\n",
      "iteration: 61 of max_iter: 100\n",
      "iteration: 62 of max_iter: 100\n",
      "iteration: 63 of max_iter: 100\n",
      "iteration: 64 of max_iter: 100, perplexity: 525.7591\n",
      "Les différents thèmes associés à la question se situent dans le fichier pyLDAVIS_tf.html\n"
     ]
    }
   ],
   "source": [
    "tf_vectorizer, lda_tf = td.get_themes(answ_lems, n_topics=5, stop_words=nlp.Defaults.stop_words)\n",
    "\n",
    "print(\"Les différents thèmes associés à la question se situent dans le fichier pyLDAVIS_tf.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hiver' 'chaud' 'froid' 'hausse' 'prix' 'travail' 'climatisation' 'doux'\n",
      " 'chauffage']\n",
      "['canicule' 'inondation' 'tempête' 'fréquent' 'violent' 'pluie'\n",
      " 'phénomène' 'vent' 'épisode']\n",
      "['pollution' 'air' 'allergie' 'qualité' 'problème' 'respiratoire'\n",
      " 'produit' 'asthme' 'déchet']\n",
      "['disparition' 'insecte' 'oiseau' 'espèce' 'biodiversité' 'animal'\n",
      " 'abeille' 'diminution' 'perte']\n",
      "['saison' 'changement' 'dérèglement' 'climat' 'catastrophe' 'modification'\n",
      " 'monde' 'faune' 'février']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlesprat/miniconda3/envs/tf/lib/python3.7/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/charlesprat/miniconda3/envs/tf/lib/python3.7/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/charlesprat/miniconda3/envs/tf/lib/python3.7/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/charlesprat/miniconda3/envs/tf/lib/python3.7/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/charlesprat/miniconda3/envs/tf/lib/python3.7/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/charlesprat/miniconda3/envs/tf/lib/python3.7/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/charlesprat/miniconda3/envs/tf/lib/python3.7/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/charlesprat/miniconda3/envs/tf/lib/python3.7/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    }
   ],
   "source": [
    "lambda_rel = 0\n",
    "for ii in range(lda_tf.components_.shape[0]):\n",
    "    print(td.get_topic_by_relevance(tf_vectorizer, lda_tf, lambd=lambda_rel, n_topic=ii))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h2>Résumé de chaque thème</h2>\n",
    "-  Résumer un grand thème en utilisant TextRank, technique de résumé extractive\n",
    "-  Spécifier le nombre de phrases que l'on souhaite pour former le résumé dans la variable `sn`\n",
    "-  Les résultats se situent dans le fichier demo.docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grand_debat.text_summarization import prepare_data, apply_page_rank_algorithm, create_titles\n",
    "from grand_debat.vectorization import sentence_to_vec\n",
    "from grand_debat.clusterisation import apply_clusterisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer le document texte en un ensemble de phrases dont la typographie est standardisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sentences = prepare_data(data_theme_response_dict, selected_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupérer la phrase la plus caractéristique de chaque thème"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentences_mixture_topics, title_sentences, titles = create_titles(clean_sentences, tf_vectorizer, lda_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Associer à chaque phrase du corpus son thème (issu de **LDA**) le plus carctéristique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_paragraph = apply_clusterisation(sentences_mixture_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Représenter chaque phrase sous la forme d'un vecteur dense. Ces vecteurs sont obtenus à partir d'embeddings entraînés à partir de l'ensemble des contributions au Grand Débat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_vectors, word_embeddings = sentence_to_vec(clean_sentences, file_model='data/word2vec.10k.100d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On applique alors l'algorithme **TextRank** à l'ensemble des phrases d'un thème pour en extraire les phrases carctéristiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indiquer le nombre de phrases qui formeront le résumé\n",
    "sn = 10\n",
    "apply_page_rank_algorithm(clean_sentences, sentences_paragraph, word_embeddings, sn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export de la synthèse sous la forme d'un document word\n",
    "-  Créer le document final contenant les résumés pour chaque thème de la question.\n",
    "-  Le processus prend environ 20 minutes sur une machine équipée d'un intel core i5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grand_debat.saving import create_final_doc, get_theme, get_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_sentence = get_theme(themes, selected_theme)\n",
    "question_sentence = get_question(questions_id, questions_title, selected_question)\n",
    "create_final_doc(title_sentences, titles, clean_sentences,\n",
    "                 sentences_paragraph, word_embeddings, theme_sentence, question_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
